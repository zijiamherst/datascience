---
title: "Lab 11: Spatial data"
author: "Ziji Zhou"
date: "October 26, 2021"
urlcolor: blue
linkcolor: blue
output:
  pdf_document:
# DO NOT CHANGE YAML BELOW THIS LINE    
    number_sections: yes
  # html_document:
  #   toc: yes
  #   toc_float: yes
classoption: fleqn
subparagraph: yes
header-includes:
  # LaTeX packages
  - \usepackage{fancyhdr,titling}\usepackage[compact]{titlesec}
  - \AtBeginEnvironment{quote}{\sffamily\large}
  # Question format (e.g., `Problem 3`)
  - > 
    \titleformat{\section}[hang]{\ifnum \value{section}>0 \newpage
                                  \else \vspace{14pt} \fi
                                  \sffamily\large}
                                  {\hspace*{-9mm}Part \thesection}{4mm}{}[]
  # Subquestion format (e.g., `3.1`)
  - >
    \titleformat{\subsection}[hang]{\vspace{14pt}\sffamily\large}
                                    {\hspace*{-9mm}\thesubsection}{4mm}{}[\vspace*{11pt}]
  # Page layout
  - >
    \pagestyle{fancy}\fancyhf{}
    \renewcommand{\headrulewidth}{0pt}
    \cfoot{\sffamily\thepage}
  # Header layout
  - >
    \lhead{\hspace*{-9mm}\sffamily\footnotesize 
            \copyright Brittney E. Bailey | STAT 231 | Lab}
  # Title layout
  - \pretitle{\hspace*{-9mm}\sffamily\footnotesize
              \copyright Brittney E. Bailey | STAT 231 | Lab
              \par \Large\bfseries \hspace*{-9mm}}
  - \posttitle{\\\hspace*{-9mm}\rule{7in}{2pt}}
  - \preauthor{\begin{flushright} \large} \postauthor{\end{flushright}}
  - \predate{\begin{flushright}\sffamily\footnotesize}
  - \postdate{\end{flushright}\vspace*{-33pt}}
  - \setlength{\droptitle}{-1in}
  # First page
  - >
    \AtBeginDocument{\sffamily\raggedright}
---

```{r setup, include = FALSE}
# load packages
library(tidyverse)
library(kableExtra)
library(leaflet)
library(ggspatial)
library(mapproj)
library(mapdata)
library(rnaturalearth)
library(oz)
library(maps)
library(sf)
library(viridis)
# library(urbnmapr)

# set code chunk defaults
knitr::opts_chunk$set(tidy = F, # display code as typed
      size = "small", # slightly smaller code font
      message = FALSE,
      warning = FALSE,
      # center figures by default
      fig.align = "center",
      comment = "\t") 

# improve digit and NA display 
options(scipen = 1, knitr.kable.NA = '')
```

# **About this lab** {-}

There are  many ways to work with spatial data in R, and this lab will introduce us to just a few.

## **Packages** {-}

The new packages we'll be working with for mapping are:

* **maps**: provides spatial data files for the world (`world`, `world.cities`, `lakes`), the US (`county`, `state`, `usa`, `us.cities`), France (`france`), Italy (`italy`), and New Zealand (`nz`). There is generally no need to load this package (the shapefiles are already loaded with **ggplot2**); 
* [**sf**](https://r-spatial.github.io/sf/): provides support for "simple features" objects, the standard data containers for spatial data; 
* **leaflet**: allows us to create dynamic maps.

Make sure you load each package (except **maps**) in the `setup` code chunk above. 

Here are some additional packages for working with spatial data or for obtaining shapefiles:

* [**ggspatial**](https://paleolimbot.github.io/ggspatial/reference/index.html): adds additional annotations, geometries, and layers for building onto static maps made with `ggplot()`; and
* **mapproj**: converts latitude and longitude into projected coordinates, primarily with `mapproject()`.
* **mapdata**: an add-on to the **maps** package (includes `china`, `japan`, and `world2Hires` for a Pacific-centric world map); 
* **rnaturalearth**: provides easy access to public domain map datasets from the Natural Earth project (tend to be higher resolution than data from the **maps** package)
* **oz**: map data for Australia and Australian states; and  
* [**urbnmapr**](https://github.com/UrbanInstitute/urbnmapr#readme): US Census Bureau shapefiles (counties, states, territories) 

\normalfont


<!-- Part 1 ------------------------------------------------------------------->
# <!-- 1 -->**Using spatial data from the maps package** The **maps** package is loaded with **ggplot2** and provides a very limited set of map data (see above). There are two ways to work with data from the maps package, outlined below.  

## <!-- 1.1 -->The first approach require use of the `map_data()` function from **ggplot2**, which turns the spatial data from the **maps** package into a data frame. The first argument, `map` takes the shapefile of interest, and the second argument, `region`, can be used to identify subregions to include (the default is  `region = "."`, which includes all subregions). To use this data, we add a `geom_polygon()` layer to the ggplot. Run the code below to convert the `world` map data into a dataframe, take a peak at what the dataframe looks like, and then plot it with `ggplot()`.

```{r}
# Get a dataframe with longitude and latitute
world_map_df <- map_data(map = "world")

head(world_map_df)
tail(world_map_df)

ggplot(world_map_df, aes(x = long, y = lat, group = group)) +
  geom_polygon(fill = "lightgrey", color = "white") +
  # Use empty theme to remove background color, axes, ticks
  theme_void()  
```

## <!-- 1.2 -->As a better alternative, we turn the **maps** spatial data into an `sf` object and make use of a `geom_sf()` layer with `ggplot()`. This approach correctly preserves the aspect ratio of the map. Run the code below to convert the `world` map data into a an `sf` object using `st_as_sf()` (from the **sf** package), take a peak at what this `sf` object looks like, and then plot the map with `ggplot()`. *Note*: Because of the more common use of the `map()` function from **purrr**, it is good practice to explicitly identify the **maps** package when using its `map()` function.

```{r}
# Obtain sf object of world map
world_map <- maps::map("world", plot = FALSE, fill = TRUE) %>% 
  st_as_sf()

head(world_map)

ggplot(data = world_map) +
  geom_sf(fill = "lightgrey", color = "white") +
  theme_void()
```

## <!-- 1.3 -->Use data from the **maps** package to create a plot of New Zealand.

```{r}

nz_map <- maps::map(database = "nz", plot = FALSE, fill = TRUE) %>%
  st_as_sf()

ggplot(data = nz_map) +
  geom_sf(fill = "lightgrey", color = "white") +
  theme_void()

```

## <!-- 1.4 -->The **maps** package also allows us to plot counties (and states) within the US. Run the code below to get a county-level map for Massachusetts.

```{r}
# Identify appropriate region value from county map data
county_df <- map_data("county") 
# Run in console to see how data appear: View(county_df)

# Create sf object for Massachusetts counties
ma_map <- maps::map("county", regions = "massachusetts",
                    plot = FALSE, fill = TRUE) %>% 
  st_as_sf()

ggplot(data = ma_map) +
  geom_sf(fill = "lightgrey", color = "white") +
  theme_void()
```

## <!-- 1.5 -->See if you can create a light grey map of the US with states outlined in black and counties outlined in white. *Hints*: remember that additional data can be read in within a geometry, and `fill = NA` may come in handy.

```{r}
state_map <- maps::map(database = "state", fill = TRUE, plot = FALSE) %>%
  st_as_sf()

county_map <- maps::map(database = "county", fill = TRUE, plot = FALSE) %>%
  st_as_sf()

ggplot() +
  geom_sf(data = county_map, fill = "lightgrey", color = "white") +
  geom_sf(data = state_map, fill = NA, color = "black") +
  theme_void()

```

<!-- Decluttering ------------------------------------------------------------->
```{r, echo = FALSE}
# cleaning environment of everything but state map before continuing
rm(county_df, 
   county_map, # you may have named your county map something different
   ma_map,
   nz_map,
   world_map,
   world_map_df)
```

<!-- Part 2 ------------------------------------------------------------------->
# <!-- 2 -->**Choropleths** We may at times want to shade or color regions based on the value of a variable to create a map called a *choropleth*. Usually the process to do this is:
> 1. Identify a data source that provides the correct spatial information needed (this may be in the form of a shapefile already, as in the **maps** package, but this can be hard to find)
> 2.  identify a data source that provides the variable of interest for coloring the map
> 3. Join the two sources together (usually much harder than it sounds!)
> 4. Create the map!

> Let's try this with data collected in July 2020 by [The Chronicle for Higher Education](https://www.chronicle.com/article/heres-a-list-of-colleges-plans-for-reopening-in-the-fall) and Davidson College's College Crisis Initiative (C2i) on colleges' reopening plans for Fall 2020. Our goal is to make a map of the US, with each state colored by the proportion of institutions in the state that were planning to be in person for Fall 2020.

## <!-- 2.1 -->We've already prepared the state spatial data (in Problem 1.5), so now we are ready to prepare the Chronicle data. Run the code below to load the Chronical data, conduct a little data wrangling to extract each school's plan (buried in the "X.1" column), and get a summary dataset with one row per state. Take the time to look at the datasets that are created and try to make sense of the steps that were taken.

```{r}
# Load data
college_plans <- read_csv("data/chronicle_plans.csv")

# Wrangle
college_plans <- college_plans %>% 
  # Some plans are embedded within HTML tags within X.1 variable
  # so we want to extract all the text between ">" and "<"
  extract(col = X.1, into = "plans_extracted",
          regex = ">(.*)<", remove = FALSE) %>% 
  # Combine extracted text with plain text of plans from X.1
  mutate(plans = case_when(is.na(plans_extracted) ~ X.1,
                           TRUE ~ plans_extracted)) %>% 
  # Remove rows without plans
  filter(plans != "Link")

head(college_plans)

# Check summary of plans
college_plans %>% count(plans)

# Count colleges per state 
colleges_per_state <- college_plans %>% 
  count(State) %>%
  rename(n_colleges = n)

head(colleges_per_state)

# Count colleges in-person per state 
college_plans_per_state <- college_plans %>% 
  count(State, plans) %>% 
  # Fill in 0s as needed (e.g., no schools in a state have in-person plans)
  ungroup() %>% 
  complete(State, plans, fill = list(n = 0)) %>% 
  filter(plans == "Planning for in-person") %>%
  rename(n_in_person = n)

head(college_plans_per_state)

# Join for final dataset
college_plan_summary <- colleges_per_state %>% 
  left_join(college_plans_per_state) %>% 
  mutate(proportion_in_person = n_in_person/n_colleges)

head(college_plan_summary)
```

<!-- Decluttering ------------------------------------------------------------->
```{r, echo = FALSE}
# clean up environment
rm(colleges_per_state, college_plans_per_state)
```

## <!-- 2.2 -->Next, we combine the state-level college planning information with the state-level mapping information.  The Chronicle of Higher Education dataset has a variable that contains two-letter abbreviations for states (e.g., "MA") whereas the state variable in the mapping dataset includes the full name of the state in lowercase letters (e.g. "massachusetts").  We can use the `state` datasets available in Base R  package (also used in our first data wrangling lab) to connect the state abbreviations to the state names. Again, take the time to look at the datasets that are created and try to make sense of the steps that were taken.

<!--
I called my state-level mapping data `state_map`. You should update the code below to match your dataset name from Problem 1.5.
-->
```{r}
# Peek at data
head(college_plan_summary)
head(state_map)

# State objects should appear in your Environment pane
data(state) 

# Create data frame with state info
state_info <- data.frame(Region = state.region,
                         # Match state variable name in map data
                         ID = tolower(state.name), 
                         # Match state variable name in summary data
                         State = state.abb)
head(state_info)

# Join datasets from the left starting with the sf object ()
college_plans_map <- state_map %>% 
  left_join(state_info) %>% 
  left_join(college_plan_summary)

head(college_plans_map)
```

<!-- Decluttering ------------------------------------------------------------->
```{r, echo = FALSE}
# clean up environment
rm(state_info, college_plan_summary)
```

## <!-- 2.3 -->Now, we can create a choropleth with `ggplot()`! Customize the plot below with a color palette of interest to you and useful labels and titles.

<!-- 
Remember we have several options for changing the color palette, e.g.:

scale_fill_distiller(palette = "...")  
scale_fill_viridis(option = "...", direction = -1)  (requires the **viridis** package)
scale_fill_brewer(palette = ...) 

-->
```{r}
ggplot(college_plans_map, aes(fill = proportion_in_person)) +
  geom_sf() +
  scale_fill_viridis(option = "magma", direction = -1) +
  labs(
    title = "Proportion of US Colleges Opening in Person",
    fill = "Proportion in Person"
  ) +
  theme_void()
```
  
## <!-- 2.4 -->Instead of summarizing the college plans across institutions in a given state, we may want to plot a point for every college and add some visual cue to indicate each individual college plan (e.g., color the points by plan category). This requires getting spatial data for each institution, and then adding a layer to our graph. This information is not included in the Chronicle dataset, so we need to find it from somewhere else.  The National Center for Education Statistics collects detailed location information for all of the higher education institutions in the US, and makes the data publicly available through [IPEDS](https://nces.ed.gov/ipeds/datacenter/Data.aspx).  Run the code below, again taking the time to look at the datasets that are created and try to make sense of the steps that were taken.

```{r}
colleges <- read_csv("data/ipeds_directory_info.csv") %>%
  janitor::clean_names() %>% 
  select(long = longitude_location_of_institution_hd2019,
         lat = latitude_location_of_institution_hd2019,
         Institution = institution_name,
         Type = control_of_institution_hd2019) %>% 
  mutate(Type = factor(Type, 
                       levels = c(1,2,3),
                       labels = c("Public", 
                                  "Private, Not-for-profit",
                                  "Private, For-profit"))) %>% 
  # Make sure coordinate projection matches our data
  st_as_sf(coords = c("long", "lat"), 
           crs = 4326, agr = "constant")

colleges_map <- colleges %>% 
  right_join(college_plans) %>% 
  # State map is only of contiguous US (sorry, Alaska and Hawaii!!)
  filter(!(State %in% c("AK", "HI")))

ggplot(college_plans_map) +
  geom_sf(aes(fill = proportion_in_person)) +
  scale_fill_viridis(option = "magma", direction = -1) +
  geom_sf(data = colleges_map, aes(color = plans)) + 
  theme_void() +
  labs(fill = "Proportion",
       color = "Plans",
       title = "Proportion of colleges planning for in-person learning for Fall 2020, by state",
       subtitle = "as of July 2020") +
  theme(legend.position = "bottom")
```

## <!-- 2.5 -->*Optional* Not all of the institutions in the Chronicle of Higher Education's file matched to an institution in the IPEDS file.  For instance, the Chronicle file has one row for Arizona State University, but the IPEDS file but has multiple rows for the same university to represent the location of the different campuses.  What other types of mismatches are there? Can you think about how to clean up the mismatches?

```{r}

```

<!-- Part 3 ------------------------------------------------------------------->
# <!-- 3 -->**Your Turn** Create a map of your choosing to display country-level data on a world map, state-level data on a country map (keeping in mind the limitations of the **maps** package and of your time to figure out one of the other shapefile packages mentioned), OR county-level data on a state map. Don't spend too long looking for unit-level data you're interested in.  I strongly recommend you use data readily available in an R package below (some sample code is provided to help you get started).  For instance:
> * the `gapminder` dataset from the **gapminder** package has (a few) country-level variables
> * the `hate_crimes` dataset from the **fivethirtyeight** package has state-level variables
> * the `states` data from Base R has a matrix of state-level variables in the object `state.x77`
> * I've also included a county-level unemployment data file from [the USDA](https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/) in the *data* subfolder. 

> **Steps**:

> 1. Create a choropleth in R
> 2. Add a title and subtitle to your figure to provide context
> 3. Add a caption to your figure with your name using the `caption` argument within the `labs` function (see example above on line 277)
> 4. Share your image on the relevant Campuswire post (`ggsave()` may come in handy).

<!-- 
If you use any of the code below, copy and paste only the code you need into a new code chunk for wrangling and then mapping your data
-->
```{r sample-code, eval = FALSE}
# Example of dataset with country information across years
library(gapminder)
data(gapminder)
head(gapminder)

# Example of dataset with state information from 2013-2014
library(fivethirtyeight)
data(hate_crimes)
head(hate_crimes)

# Example of another states dataset from Base R with state information from 1977
states_1977 <- data.frame(state.x77) %>%
  rownames_to_column(var = "State") %>%
  janitor::clean_names() %>%
  mutate(state = tolower(state))

states_1977

# Example of dataset with county-level information from 2019
# (see second tab in excel file for variable explanations)
county_employment <- readxl::read_xls("data/usda-unemployment.xls",
                                      sheet = 1,
                                      skip = 7) %>%
  janitor::clean_names()

county_employment
```

```{r your-map}
state_map <- maps::map(database = "state", fill = TRUE, plot = FALSE) %>%
  st_as_sf()

state_map <- state_map %>%
  rename(state = ID)

states_map <- state_map %>% 
  left_join(states_1977, by = c("state" = "state"))

map_plot <- ggplot(data = states_map) +
  geom_sf(aes(fill = life_exp)) + 
  scale_fill_viridis(option = "magma", direction = -1) +
  labs(
    title = "Life Expectancy in the US",
    caption = "Ziji Zhou",
    fill = "Life Expectancy"
  ) +
  theme_void()

ggsave(map_plot, filename = "Life Expectancy Map",device = jpeg)

```

<!-- Part 4 ------------------------------------------------------------------->
# <!-- 4 -->**Done early?**  Explore interactivity with **leaflet**. Modify the example with Fall 2020 college reopening plans below (can you figure out how to fill the state color by proportion of colleges in person?), or try your hand at making your map from Part 3 interactive.  

<!-- 
Interactive graphs will not knit to pdf so set `eval = FALSE` in the following code chunk
-->
```{r, eval = FALSE}
# Define a color palette over the values 0 to 1 (for proportion in person )
mypal <- colorNumeric(palette = "YlGnBu", domain = c(0,1))

# Identify Amherst College's location and pull the corresponding coordinates
ac <- colleges %>%
  filter(Institution == "Amherst College") %>% 
  pull(geometry) %>% 
  # Convert geometry coordinates to coordinate matrix
  st_coordinates()

# Create interactive map
leaflet(data = college_plans_map) %>% 
  addTiles() %>%
  addMarkers(lat = ac[1], lng = ac[2], popup = "Amherst College") %>%
  addPolygons(fillColor = topo.colors(10, alpha = NULL), 
              stroke = FALSE,
              popup = ~ paste0("State: ", ID %>% str_to_title(), "<br>",
                               "Number of schools reporting: ", n_colleges, "<br>",
                               "Number of schools planning for in-person learning: ",
                                  n_in_person, "<br>",
                               "Proportion planning for in-person learning: ",
                               proportion_in_person %>% round(2))) %>% 
  setView(lng = ac[1], lat = ac[2], zoom = 6) 
```
